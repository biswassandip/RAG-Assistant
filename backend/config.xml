<configurations>
    <LLM>
        <LLM_PROVIDER default="local">
            <option>local</option>
            <option>cloud</option>
        </LLM_PROVIDER>
        <LLM_MODEL default="llama2">
            <option>llama2</option>
            <option>mistral</option>
        </LLM_MODEL>
        <LOCAL_LLM_MODELS>
            <model name="mistral7b" path="models/mistral-7b.Q4_K_M.gguf"/>
        </LOCAL_LLM_MODELS>
        <CLOUD_LLM_MODELS>
            <model name="zephyr-7b" api_token="N/A"/>
        </CLOUD_LLM_MODELS>
    </LLM>
    
    <Embedding>
        <EMBEDDING_MODEL default="sentence-transformers/multi-qa-MiniLM-L6-cos-v1">
            <option>sentence-transformers/all-MiniLM-L6-v2</option>
            <option>sentence-transformers/multi-qa-MiniLM-L6-cos-v1</option>
            <option>intfloat/multilingual-e5-base</option>
        </EMBEDDING_MODEL>
    </Embedding>

    <HybridSearch>
        <CHUNK_SIZE min="100" max="2000">500</CHUNK_SIZE>
        <CHUNK_OVERLAP min="50" max="500">100</CHUNK_OVERLAP>
        <ALPHA min="0" max="1">0.6</ALPHA>
        <TOP_K min="1" max="20">7</TOP_K>
    </HybridSearch>

    <LLMConfig>
        <MAX_TOKENS min="256" max="2048">1024</MAX_TOKENS>
        <TEMPERATURE min="0" max="1">0.5</TEMPERATURE>
        <TOP_P min="0" max="1">0.95</TOP_P>
        <N_CTX min="512" max="4096">2048</N_CTX>
        <N_BATCH min="1" max="128">64</N_BATCH>
        <SIMILARITY_THRESHOLD min="0" max="1">0.2</SIMILARITY_THRESHOLD>
        <ENABLE_ADAPTIVE_THRESHOLD>1</ENABLE_ADAPTIVE_THRESHOLD>
        <DEFAULT_RESPONSE_LENGTH default="medium">
            <option>short</option>
            <option>medium</option>
            <option>long</option>
        </DEFAULT_RESPONSE_LENGTH>
    </LLMConfig>
</configurations>
