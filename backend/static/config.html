<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>RAG Configuration Management</title>
    <link rel="stylesheet" href="/static/config.css"> <!-- Load external CSS -->
</head>
<body>
    <div class="container">
        <h2>‚öôÔ∏è RAG Configuration Management</h2>

        <form id="config-form">
            <div class="config-group">
                <label>üåê LLM Provider</label>
                <p>Allowed values: "local" or "cloud"</p>
                <input type="text" id="llm-provider" />
            </div>
            
            <div class="config-group">
                <label>ü§ñ LLM Model</label>
                <p>Examples "llama2", "mistral"</p>
                <input type="text" id="llm-model" />
            </div>
            
            <div class="config-group">
                <label>üìÅ Local LLM Model</label>
                <p> 
                    Required when LLM Provider is "local". 
                    <br/>Examples "tinyllama", "mistral7b", "llama2"
                </p>
                <input type="text" id="local-llm-model" />
            </div>

            <div class="config-group">
                <label>üìÅ Local LLM Model Path</label>
                <p>
                    Required when LLM Provider is "local". 
                    <br/>This is the path where the model has been downloaded. 
                    <br/>Examples models/llama-2-7b.Q8_0.gguf, models/llama-2-7b-chat.Q4_K_M.gguf, models/mistral-7b-instruct-v0.1.Q4_K_M.gguf
                </p>
                <input type="text" id="model-path" />
            </div>
            
            <div class="config-group">
                <label>‚òÅÔ∏è CLOUD LLM MODEL</label>
                <p>Required when LLM Provider is "cloud"</p>
                <input type="text" id="cloud-llm-model" />
            </div>
            
            <div class="config-group">
                <label>üîë API Token</label>
                <p>Required when LLM Provider is "cloud".</p>
                <input type="text" id="api-token" />
            </div>

            <div class="config-group">
                <label>üìú CHUNK_SIZE</label>
                <p>
                    CHUNK_SIZE controls the size of document splits.
                    <br/>A smaller chunk size (e.g., 300) improves precision but may reduce recall.
                    <br/>A larger chunk size (e.g., 1000) retains more context but may return broader results.                                    </p>
                <input type="text" id="chunk-size" />
            </div>

            <div class="config-group">
                <label>üîó CHUNK_OVERLAP</label>
                <p>
                    CHUNK_OVERLAP ensures overlapping words between chunks to retain context.
                    <br/>If set too high, it increases redundancy; too low may cause loss of information.
                </p>
                <input type="text" id="chunk-overlap" />
            </div>
            
            <div class="config-group">
                <label>‚öñÔ∏è ALPHA</label>
                <p>
                    ALPHA controls the weight balance between BM25 (keyword search) and FAISS (vector search).
                    <br/>ALPHA = 1.0 ‚Üí Full BM25 (text-based keyword matching)
                    <br/>ALPHA = 0.0 ‚Üí Full FAISS (semantic search)
                    <br/>ALPHA = 0.5 ‚Üí Equal mix of BM25 & FAISS (balanced hybrid search)
                </p>
                <input type="text" id="alpha" />
            </div>
            
            <div class="config-group">
                <label>üìä TOP_K</label>
                <p>
                    TOP_K controls how many documents to retrieve before LLM processing.
                    <br/>Lower values (e.g., 3) improve response time but may reduce accuracy.
                    <br/>Higher values (e.g., 10) provide broader context but increase processing time.
                </p>
                <input type="text" id="top-k" />
            </div>
            
            <div class="config-group">
                <label>üìù MAX_TOKENS</label>
                <p>
                    MAX_TOKENS controls how long the generated response can be.
                    <br/>A higher value (e.g., 512) ensures complete answers but increases response time.
                    <br/>A lower value (e.g., 256) speeds up responses but may cause cut-off sentences.                                    
                </p>
                <input type="text" id="max-tokens" />
            </div>

            <div class="config-group">
                <label>üé≠ TEMPERATURE</label>
                <p>
                    TEMPERATURE controls randomness in the response.
                    <br/>TEMPERATURE = 0.0 ‚Üí Always gives the same response (good for factual answers).
                    <br/>TEMPERATURE = 1.0 ‚Üí More creative and varied responses (good for storytelling).
                    <br/>TEMPERATURE = 0.7 ‚Üí A balanced mix of consistency & creativity (recommended).                                    
                </p>
                <input type="text" id="temperature" />
            </div>
            
            <div class="config-group">
                <label>üéØ TOP_P</label>
                <p>
                    TOP_P controls how much of the probability mass is considered.
                    <br/>A high value (e.g., 0.95) allows more diverse responses.
                    <br/>A low value (e.g., 0.5) restricts output to highly likely words.                                                    
                </p>
                <input type="text" id="top-p" />
            </div>
            
            <div class="config-group">
                <label>üß† N_CTX</label>
                <p>
                    N_CTX (Context Window) controls how much of the conversation history is considered.
                    <br/>A low value (e.g., 512) considers less past information but is faster.
                    <br/>A high value (e.g., 2048) ensures better contextual understanding but is slower.                    
                </p>
                <input type="text" id="n-ctx" />
            </div>
            
            <div class="config-group">
                <label>üöÄ N_BATCH</label>
                <p>
                    N_BATCH controls how many tokens are processed in parallel.
                    <br/>A higher value (e.g., 64) improves performance but may use more memory.                                    
                </p>
                <input type="text" id="n-batch" />
            </div>
            
            <div class="config-group">
                <label>üî¨ EMBEDDING_MODEL</label>
                <p>
                    FAISS Embedding Model for Better Vector Search
                    <br/>Options:
                    <br/>- sentence-transformers/all-MiniLM-L6-v2 (Fast, Medium Accuracy)
                    <br/>- sentence-transformers/multi-qa-MiniLM-L6-cos-v1 (Optimized for Q&A Search)
                    <br/>- intfloat/multilingual-e5-base (Best for diverse queries)                                    
                </p>
                <input type="text" id="embedding-model" />
            </div>
            
            <div class="config-group">
                <label>üõ† ENABLE_ADAPTIVE_THRESHOLD</label>
                <p>
                    FAISS Adaptive Similarity Thresholding
                    <br/>If ENABLE_ADAPTIVE_THRESHOLD=1, the threshold is calculated dynamically.
                    <br/>If ENABLE_ADAPTIVE_THRESHOLD=0, a fixed threshold is used.                                    
                </p>
                <input type="text" id="enable-adaptive-threshold" />
            </div>

            <div class="config-group">
                <label>üîç SIMILARITY_THRESHOLD</label>
                <p>
                    Similarity threshold for FAISS retrieval
                    <br/>A lower value (e.g., 0.1) allows more results but may include irrelevant ones.
                    <br/>A higher value (e.g., 0.5) ensures only highly relevant results are returned.  
                    <br/>Only used if ENABLE_ADAPTIVE_THRESHOLD=0.                  
                </p>
                <input type="text" id="similarity-threshold" />
            </div>

            <div class="config-group">
                <label>üìè DEFAULT_RESPONSE_LENGTH</label>
                <p>Default response length (short, medium, long).</p>
                <input type="text" id="default-response-length" />
            </div>
            
            <button class="btn save-btn" id="save-button" onclick="saveConfigs(event)">üíæ Save</button>
        </form>
    </div>

    <script>
        function fetchConfigs() {
            fetch("/api/config/all")
            .then(response => response.json())
            .then(configs => {
                Object.keys(configs).forEach(key => {
                    let input = document.getElementById(key);
                    if (input) input.value = configs[key];
                });
            });
        }

        function saveConfigs(event) {
            event.preventDefault(); // Prevent form submission
            let inputs = document.querySelectorAll("#config-form input");
            let updates = {};
            inputs.forEach(input => {
                updates[input.id] = input.value;
            });

            fetch("/api/config/update", {
                method: "POST",
                headers: { "Content-Type": "application/json" },
                body: JSON.stringify(updates)
            })
            .then(response => response.json())
            .then(data => {
                alert("Configurations saved successfully!");
            });
        }

        window.onload = fetchConfigs;
    </script>
</body>
</html>
